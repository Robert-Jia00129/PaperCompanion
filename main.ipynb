{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-08T20:29:20.681459Z",
     "start_time": "2024-06-08T20:29:18.886910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"./Paper.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'A Theory of ‘The Loop’: Policy-making and Information\\nAggregation through Networks *\\nJenny S. Kim†Jo'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[0:100]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T20:30:56.801286Z",
     "start_time": "2024-06-08T20:30:56.798450Z"
    }
   },
   "id": "c1c6c49204face4a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T20:33:17.525242Z",
     "start_time": "2024-06-08T20:33:17.494826Z"
    }
   },
   "id": "40454f4573ab9a4c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T20:32:40.583662Z",
     "start_time": "2024-06-08T20:32:37.063444Z"
    }
   },
   "id": "944a0857da91e301"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input': 'What is \"The Loop?\"',\n 'context': [Document(page_content='A Theory of ‘The Loop’: Policy-making and Information\\nAggregation through Networks *\\nJenny S. Kim†John W. Patty‡\\nAbstract\\nWe describe a model of strategic, decentralized and asynchronous communication in policy-\\nmaking networks. Two central focuses of the model are the actors’ awareness of who other ac-\\ntors will talk to in the future and the sequential ordering of actors’ communications. We derive\\nconditions for truthful “cheap-talk” communication within sequential communication networks\\nand show that (1) the ordering of individuals within the network can matter above and beyond\\nindividuals’ policy preferences and degree of decision-making authority, (2) sequential commu-\\nnication throughout can engender credible communication in situations in which private, dyadic\\ncommunication will not, and (3) sequential communication can sometimes undermine credible\\ncommunication, so that exclusion of one or more “extreme” (or extremely powerful) individuals', metadata={'page': 0, 'source': './Paper.pdf'}),\n  Document(page_content='aggregation by/between at least some of the members of the group. In the next section we demon-\\nstrate more specifically how a loop can do this. In particular, the loop provides a special type of\\ncredible commitment to share information broadly.\\n17Inequality (3) understandably mirrors, but does not duplicate, Inequality (4) in Hagenbach and Koessler (2010).\\n11', metadata={'page': 10, 'source': './Paper.pdf'}),\n  Document(page_content='next proposition characterizes this formally.\\nProposition 1 Suppose that (N, α, β)are such that ˆbj≤1\\n6for all j. Then\\nM(σ;G)=n\\nfor all sources σand for all non-crossing loop networks G.\\nProposition 1 identifies situations in which the loop doesn’t matter—these are exactly the situa-\\ntions in which, regardless of the source σ, the group could simply (and credibly) sit in a room, allow\\nthe source to announce his or her signal, and presume the announcement is truthful. This point is the\\nreal import of Proposition 1: the existence of “a loop”— i.e., private sequential messaging between\\npairs of agents as opposed to simple, one-shot public messaging within the group—is arguably a\\nmethod of (partially) overcoming preference divergence within the group in pursuit of information\\naggregation by/between at least some of the members of the group. In the next section we demon-\\nstrate more specifically how a loop can do this. In particular, the loop provides a special type of', metadata={'page': 10, 'source': './Paper.pdf'}),\n  Document(page_content='The distinction between the two loops in this example is the relative power of an extremist,\\nplayer 3. By placing him or her “early” in the loop, one avoids “tempting” player 2 to lie about\\nhis or her information in an attempt to manipulate player 3’s individual policy decision. Further-\\nmore, this ameliorating effect of reversing 2 and 3’s positions in the loop is possible only because\\nof the presence of a fourth individual later in the loop (in this example, player 4). It is straightfor-\\nward to verify that neither of the networks {1,4,3,2}or{1,4,2,3}support a completely truthful\\nequilibrium. △\\n4.3 The Importance of Inclusion/Exclusion\\nThe next example is a type of converse of Example 1. While that example demonstrated the impor-\\ntance of the sequential structure of the network in supporting credible communication among three\\nagents, the following example demonstrates the potential credibility problems that can be created by', metadata={'page': 13, 'source': './Paper.pdf'})],\n 'answer': '\"The Loop\" refers to a model of strategic, decentralized, and asynchronous communication within policy-making networks. It emphasizes the importance of the sequential ordering of actors\\' communications and their awareness of future interactions. The loop structure can facilitate credible communication by providing a special type of commitment to sharing information broadly, but it can also sometimes undermine credibility, depending on the inclusion or exclusion of certain individuals and their positions within the network.'}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "results = rag_chain.invoke({\"input\": \"What is \\\"The Loop?\\\"\"})\n",
    "\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-08T20:33:45.415901Z",
     "start_time": "2024-06-08T20:33:42.751919Z"
    }
   },
   "id": "7323fc92dc1f5e7d"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'\"The Loop\" refers to a model of strategic, decentralized, and asynchronous communication within policy-making networks. It emphasizes the importance of the sequential ordering of actors\\' communications and their awareness of future interactions. The loop structure can facilitate credible communication by providing a special type of commitment to sharing information broadly, but it can also sometimes undermine credibility, depending on the inclusion or exclusion of certain individuals and their positions within the network.'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['answer']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T16:12:41.525359Z",
     "start_time": "2024-06-09T16:12:41.522484Z"
    }
   },
   "id": "ca521e874d683ffb"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "'\"The Loop\" refers to a model of strategic, decentralized, and asynchronous communication within policy-making networks. It emphasizes the importance of the sequential ordering of actors\\' communications and their awareness of future interactions. The loop structure can facilitate credible communication by providing a special type of commitment to sharing information broadly, but it can also sometimes undermine credibility, depending on the inclusion or exclusion of certain individuals and their positions within the network.'"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "StrOutputParser().invoke(results['answer'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T16:13:12.157916Z",
     "start_time": "2024-06-09T16:13:12.155463Z"
    }
   },
   "id": "2c7aadf7e3e9e8db"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from langserve import add_routes\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"cats like fish\", \"dogs like sticks\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_eugene_thoughts(query: str) -> list:\n",
    "    \"\"\"Returns Eugene's thoughts on a topic.\"\"\"\n",
    "    return retriever.get_relevant_documents(query)\n",
    "\n",
    "\n",
    "tools = [get_eugene_thoughts]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        # Please note that the ordering of the user input vs.\n",
    "        # the agent_scratchpad is important.\n",
    "        # The agent_scratchpad is a working space for the agent to think,\n",
    "        # invoke tools, see tools outputs in order to respond to the given\n",
    "        # user input. It has to come AFTER the user input.\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# We need to set streaming=True on the LLM to support streaming individual tokens.\n",
    "# Tokens will be available when using the stream_log / stream events endpoints,\n",
    "# but not when using the stream endpoint since the stream implementation for agent\n",
    "# streams action observation pairs not individual tokens.\n",
    "# See the client notebook that shows how to use the stream events endpoint.\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, streaming=True)\n",
    "\n",
    "llm_with_tools = llm.bind(functions=[convert_to_openai_function(t) for t in tools])\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_functions(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T16:12:21.190388Z",
     "start_time": "2024-06-09T16:12:20.883288Z"
    }
   },
   "id": "f1771a509a1eda96"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input': 'Hi', 'output': 'Hello! How can I assist you today?'}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(input={\"input\": \"Hi\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T16:12:21.941395Z",
     "start_time": "2024-06-09T16:12:21.195394Z"
    }
   },
   "id": "513d0b01adb9ba7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2d2ef4003a2607e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
